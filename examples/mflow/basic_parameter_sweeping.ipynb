{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Hyperparameter Sweeping\n",
    "\n",
    "**Raytheon Technologies proprietary**\n",
    "\n",
    "Export controlled - see license file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from providence_utils.hyperparameter_sweeper import HyperparameterSweeper\n",
    "from providence.dataloaders import BasicDataloaders\n",
    "from providence.training import generic_training\n",
    "from providence.paper_reproductions import NasaDatasets, NasaTransformer, NasaTransformerOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup MLFlow\n",
    "Because there's precarious details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweeper = HyperparameterSweeper(lr=[1e-2, 3e-3, 1e-3, 3e-4], batch_size=[2**_pow for _pow in range(4, 5, 6)])\n",
    "\n",
    "experiment_name = \"Providence Sweeps Demo\"\n",
    "mlflow.set_experiment(experiment_name) # returns None\n",
    "exp = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training + MLFlow logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = NasaDatasets()\n",
    "\n",
    "for sweep_params in sweeper.poll_sweeps():\n",
    "    # use the MLFlow run. May not be necessary to use context manager...\n",
    "    with mlflow.start_run(experiment_id=exp.experiment_id):\n",
    "        # log the current sweep\n",
    "        mlflow.log_params(sweep_params)\n",
    "\n",
    "        model = NasaTransformer()\n",
    "        opt = NasaTransformerOptimizer(model)\n",
    "\n",
    "        # set the learning rate through the PyTorch backdoor\n",
    "        for group in opt.opt.param_groups:\n",
    "            group['lr'] = sweep_params['lr']\n",
    "        opt = opt._replace(batch_size=sweep_params['batch_size'])\n",
    "        # changes for these parameter sweeps\n",
    "\n",
    "        dls = BasicDataloaders(train_ds, test_ds, batch_size=opt.batch_size)\n",
    "        losses = generic_training(model, opt, dls)\n",
    "\n",
    "        # log final losses\n",
    "        mlflow.log_params(\n",
    "            {\n",
    "                \"final_training_loss\": losses.training_losses[-1],\n",
    "                \"final_validation_loss\": losses.validation_losses[-1]\n",
    "            }\n",
    "        )\n",
    "        # log whatever else, say whether we got to the end of training\n",
    "        mlflow.log_param(\"training_success\", len(losses.training_losses) == opt.num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions re: refactoring\n",
    "1. Confidence towards completion of the library\n",
    "2. Tutorial notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5 (default, Jul 15 2021, 16:46:30) \n[Clang 12.0.5 (clang-1205.0.22.11)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29daccd01a8140f598b986dfe9966e4a7608d5a18dd72838d3231f8658d29959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
